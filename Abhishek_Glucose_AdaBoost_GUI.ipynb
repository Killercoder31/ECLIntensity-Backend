{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5960f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437bda59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose_mM</th>\n",
       "      <th>Intensity_RLU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>31.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>31.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>31.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>33.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>113.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Glucose_mM  Intensity_RLU\n",
       "0          0.1          31.10\n",
       "1          0.1          31.27\n",
       "2          0.1          31.45\n",
       "3          0.1          33.80\n",
       "4          0.1          33.50\n",
       "..         ...            ...\n",
       "95         1.0         116.33\n",
       "96         1.0         113.75\n",
       "97         1.0         112.25\n",
       "98         1.0         110.00\n",
       "99         1.0         112.45\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Glucose_Abhishek_ML.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cda69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =df.drop([\"Glucose_mM\"], axis=1)\n",
    "y = df[\"Glucose_mM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e05116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d303c",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bb50830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adaboost_model = AdaBoostRegressor()\n",
    "# Adaboost_model = LinearRegression()\n",
    "Adaboost_model.fit(x_train, y_train)\n",
    "# x_test\n",
    "type(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ebbb3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_Adaboost = Adaboost_model.predict(x_test)\n",
    "y_pred_Adaboost = Adaboost_model.predict([[52.1]])\n",
    "y_pred_Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433a2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Adaboost: 0.014103859103859117\n",
      "MSE for Adaboost: 0.0008166278501683857\n",
      "RMSE for Adaboost: 0.02857670117715454\n",
      "R Score Adaboost: 0.989380652143454\n"
     ]
    }
   ],
   "source": [
    "MAE_Adaboost = mean_absolute_error(y_test,y_pred_Adaboost)\n",
    "print(\"MAE for Adaboost:\",MAE_Adaboost)\n",
    "MSE_Adaboost = mean_squared_error(y_test,y_pred_Adaboost)\n",
    "print(\"MSE for Adaboost:\",MSE_Adaboost)\n",
    "RMSE_Adaboost = np.sqrt(MSE_Adaboost)\n",
    "print(\"RMSE for Adaboost:\",RMSE_Adaboost)\n",
    "r_score_Adaboost = r2_score(y_test,y_pred_Adaboost)\n",
    "print(\"R Score Adaboost:\",r_score_Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6ae2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028b21bc",
   "metadata": {},
   "source": [
    "# Tensorflow testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(101)\n",
    "# tf.set_random_seed(101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23475aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"Glucose_Abhishek_ML.xlsx\")\n",
    "# x = df.drop([\"Glucose_mM\"], axis=1)\n",
    "# y = df[\"Glucose_mM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = tf.Variable(np.random.randn(), name = \"W\")\n",
    "# b = tf.Variable(np.random.randn(), name = \"b\")\n",
    "# learning_rate = 0.01\n",
    "# training_epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hypothesis\n",
    "# y_pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# # Mean Squared Error Cost Function\n",
    "# cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n",
    "\n",
    "# # Gradient Descent Optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# # Global Variables Initializer\n",
    "# init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344af600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Starting the Tensorflow Session\n",
    "# with tf.Session() as sess:\n",
    "\t\n",
    "# \t# Initializing the Variables\n",
    "# \tsess.run(init)\n",
    "\t\n",
    "# \t# Iterating through all the epochs\n",
    "# \tfor epoch in range(training_epochs):\n",
    "\t\t\n",
    "# \t\t# Feeding each data point into the optimizer using Feed Dictionary\n",
    "# \t\tfor (_x, _y) in zip(x, y):\n",
    "# \t\t\tsess.run(optimizer, feed_dict = {X : _x, Y : _y})\n",
    "\t\t\n",
    "# \t\t# Displaying the result after every 50 epochs\n",
    "# \t\tif (epoch + 1) % 50 == 0:\n",
    "# \t\t\t# Calculating the cost a every epoch\n",
    "# \t\t\tc = sess.run(cost, feed_dict = {X : x, Y : y})\n",
    "# \t\t\tprint(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "\t\n",
    "# \t# Storing necessary values to be used outside the Session\n",
    "# \ttraining_cost = sess.run(cost, feed_dict ={X: x, Y: y})\n",
    "# \tweight = sess.run(W)\n",
    "# \tbias = sess.run(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating the predictions\n",
    "# predictions = weight * x + bias\n",
    "# print(\"Training cost =\", training_cost, \"Weight =\", weight, \"bias =\", bias, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d5c5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb5436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Glucose_Abhishek_ML.xlsx\")\n",
    "df\n",
    "x =df.drop([\"Glucose_mM\"], axis=1)\n",
    "y = df[\"Glucose_mM\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19b4f270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f7f3e28b20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "# Number of loops for training through all your data to update the parameters\n",
    "training_epochs = 10\n",
    "\n",
    "# the training dataset\n",
    "# x_train = np.linspace(0, 10, 100)\n",
    "# y_train = x_train + np.random.normal(0,1,100)\n",
    "\n",
    "# plot of data\n",
    "plt.scatter(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62f2a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(0.)\n",
    "bias = tf.Variable(0.)\n",
    "\n",
    "def linreg(x):\n",
    "    y = weight*x + bias\n",
    "    return y\n",
    "\n",
    "def squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b5108d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch count 0: Loss value: nan\n",
      "Epoch count 1: Loss value: nan\n",
      "Epoch count 2: Loss value: nan\n",
      "Epoch count 3: Loss value: nan\n",
      "Epoch count 4: Loss value: nan\n",
      "Epoch count 5: Loss value: nan\n",
      "Epoch count 6: Loss value: nan\n",
      "Epoch count 7: Loss value: nan\n",
      "Epoch count 8: Loss value: nan\n",
      "Epoch count 9: Loss value: nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "\n",
    "# Compute loss within Gradient Tape context\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_predicted = linreg(x_train)\n",
    "        loss = squared_error(y_predicted, y_train)\n",
    "\n",
    "        # Get gradients\n",
    "        gradients = tape.gradient(loss, [weight,bias])\n",
    "\n",
    "        # Adjust weights\n",
    "        weight.assign_sub(gradients[0]*learning_rate)\n",
    "        bias.assign_sub(gradients[1]*learning_rate)\n",
    "\n",
    "        # Print output\n",
    "        print(f\"Epoch count {epoch}: Loss value: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "520e1907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, linreg(x_train), 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18d77994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c045d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Glucose_Abhishek_ML.xlsx\")\n",
    "df\n",
    "x =df.drop([\"Glucose_mM\"], axis=1)\n",
    "y = df[\"Glucose_mM\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c56c25ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' dense_33/kernel:0': Shape mismatch.The variable shape (1, 1), and the assigned value shape (1,) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16748/3160393513.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'accuracy'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaboost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaboost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m           \u001b[0mtensor_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    932\u001b[0m             (f\"Cannot assign value to variable '{tensor_name}': Shape mismatch.\"\n\u001b[0;32m    933\u001b[0m              \u001b[1;34mf\"The variable shape {self._shape}, and the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign value to variable ' dense_33/kernel:0': Shape mismatch.The variable shape (1, 1), and the assigned value shape (1,) are incompatible."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Dense(15, input_dim=11, activation='relu'))\n",
    "# model.add(Dense(1, activation='linear'))tf_model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,)))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'accuracy'])\n",
    "\n",
    "model.layers[0].weights[0].assign(Adaboost_model.coef_.transpose())\n",
    "model.layers[0].bias.assign(Adaboost_model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "237d0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1035 - accuracy: 0.1000 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1156 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1033 - accuracy: 0.1000 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1155 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1046 - accuracy: 0.1000 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1153 - val_accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1026 - accuracy: 0.1000 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1151 - val_accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1033 - accuracy: 0.1000 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1150 - val_accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0200 - mae: 0.1013 - accuracy: 0.1000 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1147 - val_accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0200 - mae: 0.1030 - accuracy: 0.1000 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1146 - val_accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0198 - mae: 0.1041 - accuracy: 0.1000 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1143 - val_accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.0999 - accuracy: 0.1000 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1140 - val_accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1019 - accuracy: 0.1000 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1139 - val_accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1036 - accuracy: 0.1000 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1137 - val_accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1007 - accuracy: 0.1000 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1133 - val_accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.0995 - accuracy: 0.1000 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1131 - val_accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0192 - mae: 0.1006 - accuracy: 0.1000 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1128 - val_accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.1011 - accuracy: 0.1000 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1124 - val_accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.1012 - accuracy: 0.1000 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1121 - val_accuracy: 0.1000\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1015 - accuracy: 0.1000 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1119 - val_accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0187 - mae: 0.0966 - accuracy: 0.1000 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1116 - val_accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.1022 - accuracy: 0.1000 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1113 - val_accuracy: 0.1000\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0971 - accuracy: 0.1000 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1108 - val_accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.0985 - accuracy: 0.1000 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1105 - val_accuracy: 0.1000\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.0967 - accuracy: 0.1000 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1107 - val_accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0994 - accuracy: 0.1000 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1100 - val_accuracy: 0.1000\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.0956 - accuracy: 0.1000 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1110 - val_accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.0995 - accuracy: 0.1000 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1088 - val_accuracy: 0.1000\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.0967 - accuracy: 0.1000 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1086 - val_accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.0952 - accuracy: 0.1000 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1094 - val_accuracy: 0.1000\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0999 - accuracy: 0.1000 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1079 - val_accuracy: 0.1000\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0913 - accuracy: 0.1000 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.1070 - val_accuracy: 0.1000\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0978 - accuracy: 0.1000 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1067 - val_accuracy: 0.1000\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.0916 - accuracy: 0.1000 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1059 - val_accuracy: 0.1000\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.0935 - accuracy: 0.1000 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1054 - val_accuracy: 0.1000\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.0903 - accuracy: 0.1000 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.1075 - val_accuracy: 0.1000\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.0967 - accuracy: 0.1000 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1047 - val_accuracy: 0.1000\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0944 - accuracy: 0.1000 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.1040 - val_accuracy: 0.1000\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0896 - accuracy: 0.1000 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.1048 - val_accuracy: 0.1000\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0911 - accuracy: 0.1000 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1026 - val_accuracy: 0.1000\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0894 - accuracy: 0.1000 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1021 - val_accuracy: 0.1000\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0894 - accuracy: 0.1000 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.1014 - val_accuracy: 0.1000\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0888 - accuracy: 0.1000 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1006 - val_accuracy: 0.1000\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0884 - accuracy: 0.1000 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1026 - val_accuracy: 0.1000\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0875 - accuracy: 0.1000 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.0989 - val_accuracy: 0.1000\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0864 - accuracy: 0.1000 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0983 - val_accuracy: 0.1000\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0873 - accuracy: 0.1000 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0976 - val_accuracy: 0.1000\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0854 - accuracy: 0.1000 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0970 - val_accuracy: 0.1000\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0862 - accuracy: 0.1000 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0964 - val_accuracy: 0.1000\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0837 - accuracy: 0.1000 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0952 - val_accuracy: 0.1000\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0853 - accuracy: 0.1000 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0943 - val_accuracy: 0.1000\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0831 - accuracy: 0.1000 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.1049 - val_accuracy: 0.1000\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0828 - accuracy: 0.1000 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0925 - val_accuracy: 0.1000\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0809 - accuracy: 0.1000 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0935 - val_accuracy: 0.1000\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0818 - accuracy: 0.1000 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0909 - val_accuracy: 0.1000\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0790 - accuracy: 0.1000 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0897 - val_accuracy: 0.1000\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0776 - accuracy: 0.1000 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0900 - val_accuracy: 0.1000\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0815 - accuracy: 0.1000 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0920 - val_accuracy: 0.1000\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0785 - accuracy: 0.1000 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0868 - val_accuracy: 0.1000\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0767 - accuracy: 0.1000 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0861 - val_accuracy: 0.1000\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0742 - accuracy: 0.1000 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0849 - val_accuracy: 0.1000\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0772 - accuracy: 0.1000 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0840 - val_accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0747 - accuracy: 0.1000 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0876 - val_accuracy: 0.1000\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0752 - accuracy: 0.1000 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0818 - val_accuracy: 0.1000\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0744 - accuracy: 0.1000 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0888 - val_accuracy: 0.1000\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0727 - accuracy: 0.1000 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0812 - val_accuracy: 0.1000\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0732 - accuracy: 0.1000 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0837 - val_accuracy: 0.1000\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0712 - accuracy: 0.1000 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0792 - val_accuracy: 0.1000\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0730 - accuracy: 0.1000 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0770 - val_accuracy: 0.1000\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0699 - accuracy: 0.1000 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0774 - val_accuracy: 0.1000\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0672 - accuracy: 0.1000 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0785 - val_accuracy: 0.1000\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0675 - accuracy: 0.1000 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0735 - val_accuracy: 0.1000\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0672 - accuracy: 0.1000 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0733 - val_accuracy: 0.1000\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0662 - accuracy: 0.1000 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0723 - val_accuracy: 0.1000\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0644 - accuracy: 0.1000 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0738 - val_accuracy: 0.1000\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0669 - accuracy: 0.1000 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0745 - val_accuracy: 0.1000\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0654 - accuracy: 0.1000 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0688 - val_accuracy: 0.1000\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0658 - accuracy: 0.1000 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0821 - val_accuracy: 0.1000\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0659 - accuracy: 0.1000 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0687 - val_accuracy: 0.1000\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0661 - accuracy: 0.1000 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0811 - val_accuracy: 0.1000\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0651 - accuracy: 0.1000 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0658 - val_accuracy: 0.1000\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0617 - accuracy: 0.1000 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0737 - val_accuracy: 0.1000\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0619 - accuracy: 0.1000 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0771 - val_accuracy: 0.1000\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0644 - accuracy: 0.1000 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0806 - val_accuracy: 0.1000\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0589 - accuracy: 0.1000 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0718 - val_accuracy: 0.1000\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0631 - accuracy: 0.1000 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0689 - val_accuracy: 0.1000\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0630 - accuracy: 0.1000 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0618 - val_accuracy: 0.1000\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0583 - accuracy: 0.1000 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0604 - val_accuracy: 0.1000\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0584 - accuracy: 0.1000 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0599 - val_accuracy: 0.1000\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0641 - accuracy: 0.1000 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0591 - val_accuracy: 0.1000\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0596 - accuracy: 0.1000 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0583 - val_accuracy: 0.1000\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0606 - accuracy: 0.1000 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0663 - val_accuracy: 0.1000\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0635 - accuracy: 0.1000 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0713 - val_accuracy: 0.1000\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0639 - accuracy: 0.1000 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0697 - val_accuracy: 0.1000\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0612 - accuracy: 0.1000 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0570 - val_accuracy: 0.1000\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0634 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0625 - val_accuracy: 0.1000\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0583 - accuracy: 0.1000 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0553 - val_accuracy: 0.1000\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0589 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0612 - val_accuracy: 0.1000\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0582 - accuracy: 0.1000 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0790 - val_accuracy: 0.1000\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0562 - accuracy: 0.1000 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0572 - val_accuracy: 0.1000\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0597 - accuracy: 0.1000 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0542 - val_accuracy: 0.1000\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0647 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0556 - val_accuracy: 0.1000\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0564 - accuracy: 0.1000 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0815 - val_accuracy: 0.1000\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0645 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0619 - val_accuracy: 0.1000\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0590 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0670 - val_accuracy: 0.1000\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0605 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0540 - val_accuracy: 0.1000\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0684 - accuracy: 0.1000 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0565 - val_accuracy: 0.1000\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0748 - accuracy: 0.1000 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1221 - val_accuracy: 0.1000\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0775 - accuracy: 0.1000 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0642 - val_accuracy: 0.1000\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0678 - accuracy: 0.1000 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0895 - val_accuracy: 0.1000\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0788 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0547 - val_accuracy: 0.1000\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0594 - accuracy: 0.1000 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0951 - val_accuracy: 0.1000\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0759 - accuracy: 0.1000 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0529 - val_accuracy: 0.1000\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0628 - accuracy: 0.1000 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0797 - val_accuracy: 0.1000\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0599 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0553 - val_accuracy: 0.1000\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0617 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0587 - val_accuracy: 0.1000\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0710 - accuracy: 0.1000 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0632 - val_accuracy: 0.1000\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0623 - accuracy: 0.1000 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0745 - val_accuracy: 0.1000\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0684 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0559 - val_accuracy: 0.1000\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0569 - accuracy: 0.1000 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0844 - val_accuracy: 0.1000\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0677 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0603 - val_accuracy: 0.1000\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0831 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0547 - val_accuracy: 0.1000\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0790 - accuracy: 0.1000 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0964 - val_accuracy: 0.1000\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0641 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0679 - val_accuracy: 0.1000\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0639 - accuracy: 0.1000 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0891 - val_accuracy: 0.1000\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0777 - accuracy: 0.1000 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0797 - val_accuracy: 0.1000\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0701 - accuracy: 0.1000 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0527 - val_accuracy: 0.1000\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0638 - accuracy: 0.1000 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0872 - val_accuracy: 0.1000\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0585 - accuracy: 0.1000 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0934 - val_accuracy: 0.1000\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0639 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0542 - val_accuracy: 0.1000\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0716 - accuracy: 0.1000 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0585 - val_accuracy: 0.1000\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0713 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0611 - val_accuracy: 0.1000\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0806 - accuracy: 0.1000 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0688 - val_accuracy: 0.1000\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0602 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0659 - val_accuracy: 0.1000\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0583 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0581 - val_accuracy: 0.1000\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0629 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0555 - val_accuracy: 0.1000\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0644 - accuracy: 0.1000 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0526 - val_accuracy: 0.1000\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0728 - accuracy: 0.1000 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0905 - val_accuracy: 0.1000\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0674 - accuracy: 0.1000 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0864 - val_accuracy: 0.1000\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0750 - accuracy: 0.1000 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1163 - val_accuracy: 0.1000\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0690 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0637 - val_accuracy: 0.1000\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0679 - accuracy: 0.1000 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0780 - val_accuracy: 0.1000\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0815 - accuracy: 0.1000 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0544 - val_accuracy: 0.1000\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0595 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0546 - val_accuracy: 0.1000\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0582 - accuracy: 0.1000 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0746 - val_accuracy: 0.1000\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0526 - accuracy: 0.1000 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0527 - val_accuracy: 0.1000\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0575 - accuracy: 0.1000 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0825 - val_accuracy: 0.1000\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0691 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0582 - val_accuracy: 0.1000\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0660 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0580 - val_accuracy: 0.1000\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0677 - accuracy: 0.1000 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0755 - val_accuracy: 0.1000\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0838 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0661 - val_accuracy: 0.1000\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0746 - accuracy: 0.1000 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.1176 - val_accuracy: 0.1000\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0672 - accuracy: 0.1000 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0774 - val_accuracy: 0.1000\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0680 - accuracy: 0.1000 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0564 - val_accuracy: 0.1000\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0579 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0595 - val_accuracy: 0.1000\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0661 - accuracy: 0.1000 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0829 - val_accuracy: 0.1000\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0709 - accuracy: 0.1000 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0903 - val_accuracy: 0.1000\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0685 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0544 - val_accuracy: 0.1000\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0636 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0584 - val_accuracy: 0.1000\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0707 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0662 - val_accuracy: 0.1000\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0751 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0660 - val_accuracy: 0.1000\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0666 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0537 - val_accuracy: 0.1000\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0676 - accuracy: 0.1000 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.1005 - val_accuracy: 0.1000\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0651 - accuracy: 0.1000 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0629 - val_accuracy: 0.1000\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0770 - accuracy: 0.1000 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0842 - val_accuracy: 0.1000\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0690 - accuracy: 0.1000 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0527 - val_accuracy: 0.1000\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0668 - accuracy: 0.1000 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0528 - val_accuracy: 0.1000\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0591 - accuracy: 0.1000 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0605 - val_accuracy: 0.1000\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0611 - accuracy: 0.1000 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0529 - val_accuracy: 0.1000\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0714 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0538 - val_accuracy: 0.1000\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0576 - accuracy: 0.1000 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0752 - val_accuracy: 0.1000\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0793 - accuracy: 0.1000 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0811 - val_accuracy: 0.1000\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0669 - accuracy: 0.1000 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1236 - val_accuracy: 0.1000\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0598 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0532 - val_accuracy: 0.1000\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0630 - accuracy: 0.1000 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0679 - val_accuracy: 0.1000\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0675 - accuracy: 0.1000 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.1044 - val_accuracy: 0.1000\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0601 - accuracy: 0.1000 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0914 - val_accuracy: 0.1000\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0719 - accuracy: 0.1000 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0555 - val_accuracy: 0.1000\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0643 - accuracy: 0.1000 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0679 - val_accuracy: 0.1000\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0611 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0619 - val_accuracy: 0.1000\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0628 - accuracy: 0.1000 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0879 - val_accuracy: 0.1000\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0638 - accuracy: 0.1000 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0524 - val_accuracy: 0.1000\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0669 - accuracy: 0.1000 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0562 - val_accuracy: 0.1000\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0648 - accuracy: 0.1000 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0843 - val_accuracy: 0.1000\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0803 - accuracy: 0.1000 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0570 - val_accuracy: 0.1000\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0771 - accuracy: 0.1000 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0721 - val_accuracy: 0.1000\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0692 - accuracy: 0.1000 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0528 - val_accuracy: 0.1000\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0791 - accuracy: 0.1000 - val_loss: 0.0514 - val_mse: 0.0514 - val_mae: 0.2012 - val_accuracy: 0.1000\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0661 - accuracy: 0.1000 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0799 - val_accuracy: 0.1000\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0865 - accuracy: 0.1000 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0916 - val_accuracy: 0.1000\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0724 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0596 - val_accuracy: 0.1000\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0662 - accuracy: 0.1000 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0564 - val_accuracy: 0.1000\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0802 - accuracy: 0.1000 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0735 - val_accuracy: 0.1000\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0738 - accuracy: 0.1000 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0944 - val_accuracy: 0.1000\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0691 - accuracy: 0.1000 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0747 - val_accuracy: 0.1000\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0627 - accuracy: 0.1000 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0603 - val_accuracy: 0.1000\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0763 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0534 - val_accuracy: 0.1000\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0566 - accuracy: 0.1000 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0806 - val_accuracy: 0.1000\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0673 - accuracy: 0.1000 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0571 - val_accuracy: 0.1000\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0626 - accuracy: 0.1000 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0662 - val_accuracy: 0.1000\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0725 - accuracy: 0.1000 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0769 - val_accuracy: 0.1000\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0757 - accuracy: 0.1000 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0536 - val_accuracy: 0.1000\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0570 - accuracy: 0.1000 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0589 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=1,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc3a40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0589 - accuracy: 0.1000        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005141525994986296,\n",
       " 0.005141525994986296,\n",
       " 0.05887022614479065,\n",
       " 0.10000000149011612]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7b6d658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F7F8A18550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test).flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d9e9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0589 - accuracy: 0.1000\n",
      "Test loss: 0.005141526460647583\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18770d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733c140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
